# -*- coding: utf-8 -*-
"""CS767 Assignment 8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BePQmoDMhkblgZ5EEHAXyp_zV0LMMoiP
"""

import matplotlib.pyplot as plt
import numpy as np
import os
import torch
from torchvision import datasets, transforms
from keras.preprocessing.image import ImageDataGenerator
from keras import backend as K
import keras
import tensorflow as tf
from keras.utils import np_utils
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential, Model,load_model
from keras.callbacks import EarlyStopping,ModelCheckpoint
from google.colab.patches import cv2_imshow
from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D
from keras.preprocessing import image
from keras.initializers import glorot_uniform

from tensorflow.keras.datasets import cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

## Let us look at the data
class_names = ["airplane", "automobile", "bird", "cat", "deer", 
				"dog", "frog", "horse", "ship", "truck"]
n_rows = 4
n_cols = 10
plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))
for row in range(n_rows):
    for col in range(n_cols):
        index = n_cols * row + col
        plt.subplot(n_rows, n_cols, index + 1)
        plt.imshow(transforms.ToPILImage()(x_train[index]))
        plt.axis('off')
        plt.title(class_names[int(y_train[index])], fontsize=12)
plt.subplots_adjust(wspace=0.2, hspace=0.5)
plt.show()

InitSeed = 767
tf.random.set_seed(InitSeed)
np.random.seed( InitSeed)


#min-max normalization - min is 0 so just divide by max
x_train = x_train/255
x_test = x_test /255

x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1,random_state=767)

y_train = keras.utils.np_utils.to_categorical(y_train, num_classes=10)
y_test = keras.utils.np_utils.to_categorical(y_test, num_classes=10)
y_valid = keras.utils.np_utils.to_categorical(y_valid, num_classes=10)

print("Shape of training data:")
print(x_train.shape)
print(y_train.shape)
print("Shape of test data:")
print(x_test.shape)
print(y_test.shape)
print("Shape of valid data:")
print(x_valid.shape)
print(y_valid.shape)

"""## Build ResNet50"""

# build ResidualUnit Layer
 
class ResidualUnit(keras.layers.Layer):
  def __init__(self, filters, f=1, s=2,layertype="identity", strides = 1,activation="relu", **kwargs):
    super().__init__(**kwargs)
    self.f = f
    self.s = s
    self.layertype = layertype
    self.strides = strides
    self.activation = keras.activations.get(activation) 
    self.identity_layers = [
                    keras.layers.Conv2D(filters, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=glorot_uniform(seed=0)),
                    keras.layers.BatchNormalization(),
                    self.activation,
                    keras.layers.Conv2D(filters, kernel_size=(self.f, self.f), strides=(1, 1), padding='same', kernel_initializer=glorot_uniform(seed=0)),
                    keras.layers.BatchNormalization(),
                    self.activation,
                    keras.layers.Conv2D(filters*4, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=glorot_uniform(seed=0)),
                    keras.layers.BatchNormalization()]
    self.convolution_layers = [
                    keras.layers.Conv2D(filters, kernel_size=(1, 1), strides=(self.s, self.s), padding='valid', kernel_initializer=glorot_uniform(seed=0)),
                    keras.layers.BatchNormalization(),
                    self.activation,
                    keras.layers.Conv2D(filters, kernel_size=(self.f, self.f), strides=(1, 1), padding='same', kernel_initializer=glorot_uniform(seed=0)),
                    keras.layers.BatchNormalization(),
                    self.activation,
                    keras.layers.Conv2D(filters*4, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=glorot_uniform(seed=0)),
                    keras.layers.BatchNormalization()]
    self.skip_layers = [] 
    if self.strides > 1:
        self.skip_layers = [
            keras.layers.Conv2D(filters=filters*4, kernel_size=(1, 1), strides=(self.s, self.s), padding='valid', kernel_initializer=glorot_uniform(seed=0)),
            keras.layers.BatchNormalization()]


  def call(self, inputs): 
    Z = inputs
    if self.layertype =="identity":
      for layer in self.identity_layers: 
        Z = layer(Z)
    else:
      for layer in self.convolution_layers: 
        Z = layer(Z)
    skip_Z = inputs
    for layer in self.skip_layers:
      skip_Z = layer(skip_Z)
    return self.activation(Z + skip_Z)

# buld the entire network
inner_model = keras.models.Sequential()

inner_model.add(keras.layers.ZeroPadding2D((3, 3)))

#Stage 1
inner_model.add(keras.layers.Conv2D(64, (7, 7), strides=(2, 2), kernel_initializer=glorot_uniform(seed=0)))
inner_model.add(keras.layers.BatchNormalization())
inner_model.add(keras.layers.Activation("relu")) 
inner_model.add(keras.layers.MaxPool2D(pool_size=3, strides=2)) 

#Stage 2
inner_model.add(ResidualUnit(filters=64,layertype="convolution", f=3, s=1, strides=2)) 
inner_model.add(ResidualUnit(filters=64,layertype="identity",f=3)) 
inner_model.add(ResidualUnit(filters=64,layertype="identity", f=3)) 

#Stage 3
inner_model.add(ResidualUnit(filters=128,layertype="convolution", f=3, s=2, strides=2))
inner_model.add(ResidualUnit(filters=128,layertype="identity", f=3))
inner_model.add(ResidualUnit(filters=128,layertype="identity", f=3)) 
inner_model.add(ResidualUnit(filters=128,layertype="identity", f=3)) 

#Stage 4
inner_model.add(ResidualUnit(filters=256,layertype="convolution", f=3, s=2, strides=2))
inner_model.add(ResidualUnit(filters=256,layertype="identity", f=3)) 
inner_model.add(ResidualUnit(filters=256,layertype="identity", f=3)) 
inner_model.add(ResidualUnit(filters=256,layertype="identity", f=3)) 
inner_model.add(ResidualUnit(filters=256,layertype="identity", f=3)) 
inner_model.add(ResidualUnit(filters=256,layertype="identity", f=3)) 

#Stage 5
inner_model.add(ResidualUnit(filters=512,layertype="convolution", f=3,s=2, strides=2))
inner_model.add(ResidualUnit(filters=512,layertype="identity", f=3)) 
inner_model.add(ResidualUnit(filters=512,layertype="identity", f=3)) 

inner_model.add(keras.layers.AveragePooling2D(pool_size=(2, 2), padding='same'))
inner_model.add(keras.layers.Flatten())
inner_model.add(keras.layers.Dense(10, activation="softmax", kernel_initializer = glorot_uniform(seed=0)))

"""## Model without transfer learning"""

InitSeed = 767
tf.random.set_seed(InitSeed)
np.random.seed( InitSeed)

inner_model.compile(loss="categorical_crossentropy",  optimizer="adam", metrics=["accuracy"])

inner_model.fit(x_train, y_train, epochs = 5, batch_size = 32, validation_data=(x_valid,y_valid))

inner_model.summary()

inner_model.evaluate(x_test, y_test, batch_size=64)

"""## Model with transfer learning"""

x_train = tf.keras.applications.resnet50.preprocess_input(x_train)
x_valid = tf.keras.applications.resnet50.preprocess_input(x_valid)
x_test = tf.keras.applications.resnet50.preprocess_input(x_test)

#instantiate a base model with pre-trained weights
KerasModel=tf.keras.applications.resnet50.ResNet50(include_top=False, input_shape=(32,32,3),classes=10, weights='imagenet')

#freeze the base model
for layer in KerasModel.layers:
    layer.trainable = False

new_model = keras.models.Sequential()
new_model.add(KerasModel)
new_model.add(keras.layers.Flatten())
new_model.add(keras.layers.Dense(10, activation="softmax"))

new_model.summary()

InitSeed = 767
tf.random.set_seed(InitSeed)
np.random.seed( InitSeed)

new_model.compile(loss="categorical_crossentropy",  optimizer="adam", metrics=["accuracy"])

new_model.fit(x_train, y_train, epochs = 10, batch_size = 32, validation_data=(x_valid,y_valid))

new_model.evaluate(x_test, y_test, batch_size=64)

"""## Attempt 2"""

#instantiate a base model with pre-trained weights
KerasModel=tf.keras.applications.resnet50.ResNet50(include_top=False, input_shape=(224,224,3),classes=10, weights='imagenet')

#freeze the base model
for layer in KerasModel.layers:
    layer.trainable = False

new_model2 = keras.models.Sequential()
new_model2.add(tf.keras.layers.UpSampling2D(size=(7,7)))
new_model2.add(KerasModel)
new_model2.add(tf.keras.layers.GlobalAveragePooling2D())
new_model2.add(keras.layers.Flatten())
new_model2.add(keras.layers.Dense(10, activation="softmax"))

InitSeed = 767
tf.random.set_seed(InitSeed)
np.random.seed( InitSeed)

new_model2.compile(loss="categorical_crossentropy",  optimizer="SGD", metrics=["accuracy"])

new_model2.fit(x_train, y_train, epochs = 10, batch_size = 32, validation_data=(x_valid,y_valid))

new_model2.evaluate(x_test, y_test, batch_size=64)

"""## Attempt 3"""

InitSeed = 767
tf.random.set_seed(InitSeed)
np.random.seed( InitSeed)

(x_train, y_train), (x_test, y_test) = cifar10.load_data()


x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1,random_state=767)

y_train = keras.utils.np_utils.to_categorical(y_train, num_classes=10)
y_test = keras.utils.np_utils.to_categorical(y_test, num_classes=10)
y_valid = keras.utils.np_utils.to_categorical(y_valid, num_classes=10)

x_train = tf.keras.applications.resnet50.preprocess_input(x_train)
x_valid = tf.keras.applications.resnet50.preprocess_input(x_valid)
x_test = tf.keras.applications.resnet50.preprocess_input(x_test)

#instantiate a base model with pre-trained weights
KerasModel=tf.keras.applications.resnet50.ResNet50(include_top=False, input_shape=(224,224,3),classes=10, weights='imagenet')

#freeze the base model
for layer in KerasModel.layers:
    layer.trainable = False

new_model3 = keras.models.Sequential()
new_model3.add(tf.keras.layers.UpSampling2D(size=(7,7)))
new_model3.add(KerasModel)
new_model3.add(tf.keras.layers.GlobalAveragePooling2D())
new_model3.add(keras.layers.Flatten())
new_model3.add(keras.layers.Dense(10, activation="softmax"))

InitSeed = 767
tf.random.set_seed(InitSeed)
np.random.seed( InitSeed)

new_model3.compile(loss="categorical_crossentropy",  optimizer="SGD", metrics=["accuracy"])

new_model3.fit(x_train, y_train, epochs = 3, batch_size = 32, validation_data=(x_valid,y_valid))

new_model3.evaluate(x_test, y_test, batch_size=64)

"""## Attempt to add pretrained model to the model I built"""

#instantiate a base model with pre-trained weights
KerasModel=tf.keras.applications.resnet50.ResNet50(include_top=False, input_shape=(224,224,3),classes=10, weights='imagenet')

#freeze the base model
for layer in KerasModel.layers:
    layer.trainable = False

new_model4 = keras.models.Sequential()
new_model4.add(tf.keras.layers.UpSampling2D(size=(7,7)))
new_model4.add(KerasModel)
new_model4.add(inner_model)

InitSeed = 767
tf.random.set_seed(InitSeed)
np.random.seed( InitSeed)

new_model4.compile(loss="categorical_crossentropy",  optimizer="SGD", metrics=["accuracy"])

new_model4.fit(x_train, y_train, epochs = 3, batch_size = 32, validation_data=(x_valid,y_valid))

new_model4.evaluate(x_test, y_test, batch_size=64)

new_model.summary()
