# -*- coding: utf-8 -*-
"""Group_Assignment_2-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zy1BAMeOGLmqOleozJJfJHkEQQlTzC2f
"""

"""
Matthew Polanco and Thomas Olson
Class: CS 767
Date: 03/30/22
Group Assignment 2
CNN vs MLP on fashion mnist dataset.
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
import matplotlib.pyplot as plt
from keras import models
from keras import layers
import plotly.graph_objs as go
from plotly import tools
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot



print(tf.__version__)
print(keras.__version__)

(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()

X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]
y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]

X_mean = X_train.mean(axis=0, keepdims=True)
X_std = X_train.std(axis=0, keepdims=True) + 1e-7
X_train = (X_train - X_mean) / X_std
X_valid = (X_valid - X_mean) / X_std
X_test = (X_test - X_mean) / X_std

X_train = X_train[..., np.newaxis]
X_valid = X_valid[..., np.newaxis]
X_test = X_test[..., np.newaxis]

"""## Part 1

### Without Dropout
"""

keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential()
#Add first Conv2D layer
model.add(keras.layers.Conv2D(filters=64, kernel_size=7, strides=1,padding="SAME", activation="relu",input_shape=(28, 28, 1)))
#Add max pooling 1
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2))) 
#Add second hidden Conv2D layer
model.add(keras.layers.Conv2D(filters=64, kernel_size=3, strides=1,padding="SAME", activation="relu"))
#Add max pooling 2
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
#Add third hidden Conv2D layer
model.add(keras.layers.Conv2D(filters=64, kernel_size=3, strides=1,padding="SAME", activation="relu"))
#Add max pooling 3
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
#Add flatten layer before dense layer
model.add(keras.layers.Flatten())
#Add hidden dense layer
model.add(keras.layers.Dense(64, activation="relu"))
#Add output layer
model.add(keras.layers.Dense(10, activation="softmax"))

model.summary()

model.compile(loss="sparse_categorical_crossentropy", optimizer='nadam', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=20,verbose = 1,validation_data=(X_valid, y_valid))

score = model.evaluate(X_test, y_test)
print('Test score:', score[0])
print('Test accuracy:', score[1])

def create_trace(x,y,ylabel,color):
        trace = go.Scatter(
            x = x,y = y,
            name=ylabel,
            marker=dict(color=color),
            mode = "markers+lines",
            text=x
        )
        return trace
    
def plot_accuracy_and_loss(model_fit):
    acc = model_fit.history['accuracy']
    val_acc = model_fit.history['val_accuracy']
    loss = model_fit.history['loss']
    val_loss = model_fit.history['val_loss']
    epochs = list(range(1,len(acc)+1))
    
    trace_ta = create_trace(epochs,acc,"Training accuracy", "Green")
    trace_va = create_trace(epochs,val_acc,"Validation accuracy", "Red")
    trace_tl = create_trace(epochs,loss,"Training loss", "Blue")
    trace_vl = create_trace(epochs,val_loss,"Validation loss", "Magenta")
   
    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',
                                                             'Training and validation loss'))
    fig.append_trace(trace_ta,1,1)
    fig.append_trace(trace_va,1,1)
    fig.append_trace(trace_tl,1,2)
    fig.append_trace(trace_vl,1,2)
    fig['layout']['xaxis'].update(title = 'Epoch')
    fig['layout']['xaxis2'].update(title = 'Epoch')
    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])
    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])

    
    iplot(fig, filename='accuracy-loss')

plot_accuracy_and_loss(history)

"""### With Dropout"""

keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential()
#Add first Conv2D layer
model.add(keras.layers.Conv2D(filters=64, kernel_size=7, strides=1,padding="SAME", activation="relu",input_shape=(28, 28, 1)))
#Add max pooling 1
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2))) 
#Add second hidden Conv2D layer
model.add(keras.layers.Conv2D(filters=64, kernel_size=3, strides=1,padding="SAME", activation="relu"))
#Add max pooling 2
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
#Add third hidden Conv2D layer
model.add(keras.layers.Conv2D(filters=64, kernel_size=3, strides=1,padding="SAME", activation="relu"))
#Add max pooling 3
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
#Add flatten layer before dense layer
model.add(keras.layers.Flatten())
#Add hidden dense layer
model.add(keras.layers.Dense(64, activation="relu"))
#Add dropout
model.add(keras.layers.Dropout(rate=0.5))
#Add output layer
model.add(keras.layers.Dense(10, activation="softmax"))

model.summary()

model.compile(loss="sparse_categorical_crossentropy", optimizer='nadam', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=20,verbose = 1,validation_data=(X_valid, y_valid))

score = model.evaluate(X_test, y_test)
print('Test score:', score[0])
print('Test accuracy:', score[1])

def create_trace(x,y,ylabel,color):
        trace = go.Scatter(
            x = x,y = y,
            name=ylabel,
            marker=dict(color=color),
            mode = "markers+lines",
            text=x
        )
        return trace
    
def plot_accuracy_and_loss(model_fit):
    acc = model_fit.history['accuracy']
    val_acc = model_fit.history['val_accuracy']
    loss = model_fit.history['loss']
    val_loss = model_fit.history['val_loss']
    epochs = list(range(1,len(acc)+1))
    
    trace_ta = create_trace(epochs,acc,"Training accuracy", "Green")
    trace_va = create_trace(epochs,val_acc,"Validation accuracy", "Red")
    trace_tl = create_trace(epochs,loss,"Training loss", "Blue")
    trace_vl = create_trace(epochs,val_loss,"Validation loss", "Magenta")
   
    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',
                                                             'Training and validation loss'))
    fig.append_trace(trace_ta,1,1)
    fig.append_trace(trace_va,1,1)
    fig.append_trace(trace_tl,1,2)
    fig.append_trace(trace_vl,1,2)
    fig['layout']['xaxis'].update(title = 'Epoch')
    fig['layout']['xaxis2'].update(title = 'Epoch')
    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])
    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])

    
    iplot(fig, filename='accuracy-loss')

plot_accuracy_and_loss(history)

"""## Part 2

### Without Dropout
"""

keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential()
model.add(keras.layers.Flatten(input_shape=[28, 28, 1]))
#Add first hidden dense layer
model.add(keras.layers.Dense(64, activation="relu"))
#Add second hidden dense layer
model.add(keras.layers.Dense(64, activation="relu"))
#Add third hidden dense layer
model.add(keras.layers.Dense(64, activation="relu"))
#Add fourth hidden dense layer
model.add(keras.layers.Dense(64, activation="relu"))
#Add output layer
model.add(keras.layers.Dense(10, activation="softmax"))

model.summary()

model.compile(loss="sparse_categorical_crossentropy", optimizer='nadam', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=20,verbose = 1,validation_data=(X_valid, y_valid))

score = model.evaluate(X_test, y_test)
print('Test score:', score[0])
print('Test accuracy:', score[1])

def create_trace(x,y,ylabel,color):
        trace = go.Scatter(
            x = x,y = y,
            name=ylabel,
            marker=dict(color=color),
            mode = "markers+lines",
            text=x
        )
        return trace
    
def plot_accuracy_and_loss(model_fit):
    acc = model_fit.history['accuracy']
    val_acc = model_fit.history['val_accuracy']
    loss = model_fit.history['loss']
    val_loss = model_fit.history['val_loss']
    epochs = list(range(1,len(acc)+1))
    
    trace_ta = create_trace(epochs,acc,"Training accuracy", "Green")
    trace_va = create_trace(epochs,val_acc,"Validation accuracy", "Red")
    trace_tl = create_trace(epochs,loss,"Training loss", "Blue")
    trace_vl = create_trace(epochs,val_loss,"Validation loss", "Magenta")
   
    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',
                                                             'Training and validation loss'))
    fig.append_trace(trace_ta,1,1)
    fig.append_trace(trace_va,1,1)
    fig.append_trace(trace_tl,1,2)
    fig.append_trace(trace_vl,1,2)
    fig['layout']['xaxis'].update(title = 'Epoch')
    fig['layout']['xaxis2'].update(title = 'Epoch')
    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])
    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])

    
    iplot(fig, filename='accuracy-loss')

plot_accuracy_and_loss(history)

"""### With Dropout"""

keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential()
model.add(keras.layers.Flatten(input_shape=[28, 28, 1]))
#Add first hidden dense layer
model.add(keras.layers.Dense(64, activation="relu"))
#Add dropout
model.add(keras.layers.Dropout(rate=0.5))
#Add second hidden dense layer
model.add(keras.layers.Dense(64, activation="relu"))
#Add dropout
model.add(keras.layers.Dropout(rate=0.5))
#Add third hidden dense layer
model.add(keras.layers.Dense(64, activation="relu"))
#Add dropout
model.add(keras.layers.Dropout(rate=0.5))
#Add fourth hidden dense layer
model.add(keras.layers.Dense(64, activation="relu"))
#Add dropout
model.add(keras.layers.Dropout(rate=0.5))
#Add output layer
model.add(keras.layers.Dense(10, activation="softmax"))

model.summary()

model.compile(loss="sparse_categorical_crossentropy", optimizer='nadam', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=20,verbose = 1,validation_data=(X_valid, y_valid))

score = model.evaluate(X_test, y_test)
print('Test score:', score[0])
print('Test accuracy:', score[1])

def create_trace(x,y,ylabel,color):
        trace = go.Scatter(
            x = x,y = y,
            name=ylabel,
            marker=dict(color=color),
            mode = "markers+lines",
            text=x
        )
        return trace
    
def plot_accuracy_and_loss(model_fit):
    acc = model_fit.history['accuracy']
    val_acc = model_fit.history['val_accuracy']
    loss = model_fit.history['loss']
    val_loss = model_fit.history['val_loss']
    epochs = list(range(1,len(acc)+1))
    
    trace_ta = create_trace(epochs,acc,"Training accuracy", "Green")
    trace_va = create_trace(epochs,val_acc,"Validation accuracy", "Red")
    trace_tl = create_trace(epochs,loss,"Training loss", "Blue")
    trace_vl = create_trace(epochs,val_loss,"Validation loss", "Magenta")
   
    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',
                                                             'Training and validation loss'))
    fig.append_trace(trace_ta,1,1)
    fig.append_trace(trace_va,1,1)
    fig.append_trace(trace_tl,1,2)
    fig.append_trace(trace_vl,1,2)
    fig['layout']['xaxis'].update(title = 'Epoch')
    fig['layout']['xaxis2'].update(title = 'Epoch')
    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])
    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])

    
    iplot(fig, filename='accuracy-loss')

plot_accuracy_and_loss(history)

